#![allow(clippy::upper_case_acronyms)]

use async_trait::async_trait;
use exn::{Exn, OptionExt, ResultExt};
use serde_json::Value as JsonValue;
use url::Url;

use reqwest::{Client, StatusCode};
use std::{any::Any, io::Cursor, str::FromStr};

use crate::{
    json_extract,
    repo::{Endpoint, FileMeta, RepoError},
    Checksum, DirMeta, Entry, Repository,
};

// https://www.dataone.org/
// API doc at https://dataoneorg.github.io/api-documentation/
// XXX: read about https://dataoneorg.github.io/api-documentation/design/DataPackage.html?utm_source=chatgpt.com
// not planned because Dataone is extremly slow in HTTP response.
// XXX: potentially it support: https://dataoneorg.github.io/api-documentation/apis/MN_APIs.html#MNPackage.getPackage
#[derive(Debug)]
pub struct Dataone {
    #[allow(dead_code)]
    base_url: Url,
}

impl Dataone {
    #[must_use]
    pub fn new(base_url: Url) -> Self {
        Dataone { base_url }
    }
}

#[async_trait]
impl Repository for Dataone {
    fn root_url(&self, id: &str) -> Url {
        // the dashboard can be at https://data.ess-dive.lbl.gov/view/doi%3A10.15485%2F1971251
        // the xml to describe datasets are all at https://cn.dataone.org/cn/v2/object/

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        // - `join` cannot fail for this URL scheme
        let url = Url::from_str("https://cn.dataone.org/cn/v2/object/").unwrap();
        url.join(id).expect("cannot parse new url")
    }
    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        // TODO: I use xmltree at the moment, which load full xml and then the parsed tree in
        // memory, it can be improve by buf and async when performance requirements comes for
        // DataOne repositories.
        let bytes = resp.bytes().await.map_err(|_| RepoError {
            message: "Failed to get bytes from response".to_string(),
        })?;
        let meta_tree = xmltree::Element::parse(Cursor::new(bytes)).map_err(|_| RepoError {
            message: "Failed to parse XML".to_string(),
        })?;

        let mut entries = Vec::new();
        if let Some(dataset_elem) = meta_tree.get_child("dataset") {
            for data_elem in &dataset_elem.children {
                if let Some(elem) = data_elem.as_element() {
                    if elem.name == "otherEntity" || elem.name == "dataTable" {
                        let download_url = elem
                            .get_child("physical")
                            .and_then(|p| p.get_child("distribution"))
                            .and_then(|d| {
                                d.get_child("online").and_then(|o| {
                                    o.get_child("url").and_then(|url_elem| {
                                        if url_elem
                                            .attributes
                                            .get("function")
                                            .is_some_and(|f| f == "download")
                                        {
                                            url_elem.get_text().map(|s| s.to_string())
                                        } else {
                                            None
                                        }
                                    })
                                })
                            })
                            .ok_or_raise(|| RepoError {
                                message: format!(
                                    "not found download url at {}, through 'physical.distribution.online.url.function.download", 
                                    dir.api_url.as_str()),
                            })?;
                        let download_url = Url::from_str(&download_url).map_err(|_| RepoError {
                            message: format!("{download_url} is not a valid download url"),
                        })?;

                        let name = elem
                            .get_child("entityName")
                            .and_then(|e| e.get_text().map(|s| s.to_string()))
                            .ok_or_raise(|| RepoError {
                                message: "name not found".to_string(),
                            })?;

                        let size = elem
                            .get_child("physical")
                            .and_then(|p| p.get_child("size"))
                            .and_then(|s| {
                                s.get_text().map(|s| {
                                    s.parse::<u64>().map_err(|err| RepoError {
                                        message: format!("cannot parse file physical size, {err}"),
                                    })
                                })
                            })
                            .transpose()?;

                        let endpoint = Endpoint {
                            parent_url: dir.api_url.clone(),
                            key: Some(
                                "dataset.physical.distribution.online.url[@function='download']"
                                    .to_string(),
                            ),
                        };

                        let file =
                            FileMeta::new(dir.join(&name), endpoint, download_url, size, vec![]);
                        entries.push(Entry::File(file));
                    }
                }
            }
        }

        Ok(entries)
    }
    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://hal.science/
// API root url at https://hal.science/<id>?
#[derive(Debug)]
pub struct HalScience;

impl HalScience {
    #[must_use]
    pub fn new() -> Self {
        HalScience
    }
}

impl Default for HalScience {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl Repository for HalScience {
    fn root_url(&self, id: &str) -> Url {
        // HAL Search API endpoint
        // can get files of a record by following search api call, e.g. for 'cel-01830944'
        // curl "https://api.archives-ouvertes.fr/search/?q=halId_s:cel-01830943&wt=json&fl=halId_s,fileMain_s,files_s,fileType_s"
        //
        // it returns
        // {
        //   "response":{
        //     "numFound":1,
        //     "start":0,
        //     "maxScore":5.930896,
        //     "numFoundExact":true,
        //     "docs":[{
        //       "halId_s":"cel-01830944",
        //       "fileMain_s":"https://hal.science/cel-01830944/document",
        //       "files_s":["https://hal.science/cel-01830944/file/MAILLOT_Cours_inf340-systemes_information.pdf"],
        //       "fileType_s":["file"]
        //     }]
        //   }
        // }âŽ
        //

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        let mut url = Url::from_str("https://api.archives-ouvertes.fr/search/").unwrap();

        url.query_pairs_mut()
            .append_pair("q", &format!("halId_s:{id}"))
            .append_pair("wt", "json")
            .append_pair("fl", "halId_s,fileMain_s,files_s,fileType_s");

        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;
        let files = resp
            .get("response")
            .and_then(|d| d.get("docs"))
            .and_then(|docs| docs.get(0))
            .and_then(|d| d.get("files_s"))
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "field with key 'data' not resolve to an json array".to_string(),
            })?;

        let mut entries = Vec::with_capacity(files.len());
        for (idx, filej) in files.iter().enumerate() {
            let endpoint = Endpoint {
                parent_url: dir.api_url.clone(),
                key: Some(format!("response.docs.0.files_s.{idx}")),
            };
            let JsonValue::String(download_url) = filej else {
                todo!()
            };
            let filename = download_url
                .split('/')
                .next_back()
                .ok_or_else(|| RepoError {
                    message: format!("didn't get filename from '{download_url}'"),
                })?;
            let download_url = Url::from_str(download_url).or_raise(|| RepoError {
                message: format!("invalid download url '{download_url}'"),
            })?;
            let file = FileMeta::new(
                dir.join(&format!("{filename}.pdf")),
                endpoint,
                download_url,
                None,
                vec![],
            );
            entries.push(Entry::File(file));
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://arxiv.org/
// API root url at https://arxiv.org/pdf/
#[derive(Debug)]
pub struct Arxiv;

impl Arxiv {
    #[must_use]
    pub fn new() -> Self {
        Arxiv
    }
}

impl Default for Arxiv {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl Repository for Arxiv {
    fn root_url(&self, id: &str) -> Url {
        // https://arxiv.org/pdf/<id> to get the record pdf

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        // - `path_segments_mut` cannot fail for this URL scheme
        let mut url = Url::from_str("https://arxiv.org").unwrap();
        url.path_segments_mut().unwrap().extend(["pdf", id]);
        url
    }

    async fn list(&self, _client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let root_url = dir.root_url();
        // safe to unwrap, because I create the root_url
        let name: Vec<&str> = root_url.path_segments().unwrap().collect::<Vec<_>>();
        let name = name[1];
        let download_url = root_url.clone();
        let endpoint = Endpoint {
            parent_url: dir.root_url(),
            key: Some(name.to_string()),
        };
        let file = FileMeta::new(
            dir.join(&format!("{name}.pdf")),
            endpoint,
            download_url,
            None,
            vec![],
        );

        Ok(vec![Entry::File(file)])
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://osf.io/
// API root url at https://api.osf.io/v2/nodes/
#[derive(Debug)]
pub struct OSF;

impl OSF {
    #[must_use]
    pub fn new() -> Self {
        OSF
    }
}

impl Default for OSF {
    fn default() -> Self {
        Self::new()
    }
}

#[async_trait]
impl Repository for OSF {
    fn root_url(&self, id: &str) -> Url {
        // https://api.osf.io/v2/nodes/<id>/files to start for every dateset entry

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        // - `path_segments_mut` cannot fail for this URL scheme
        let mut url = Url::from_str("https://api.osf.io/v2/nodes/").unwrap();
        url.path_segments_mut().unwrap().extend([id, "files"]);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;
        let files = resp
            .get("data")
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "field with key 'data' not resolve to an json array".to_string(),
            })?;

        let mut entries = Vec::with_capacity(files.len());
        for (idx, filej) in files.iter().enumerate() {
            let endpoint = Endpoint {
                parent_url: dir.api_url.clone(),
                key: Some(format!("data.{idx}")),
            };
            let name: String = json_extract(filej, "attributes.name").or_raise(|| RepoError {
                message: "fail to extracting 'attributes.name' as String from json".to_string(),
            })?;
            let kind: String = json_extract(filej, "attributes.kind").or_raise(|| RepoError {
                message: "fail to extracting 'attributes.kind' as String from json".to_string(),
            })?;
            match kind.as_ref() {
                "file" => {
                    let size: u64 =
                        json_extract(filej, "attributes.size").or_raise(|| RepoError {
                            message: "fail to extracting 'attributes.size' as u64 from json"
                                .to_string(),
                        })?;
                    let download_url: String =
                        json_extract(filej, "links.download").or_raise(|| RepoError {
                            message: "fail to extracting 'links.download' as String from json"
                                .to_string(),
                        })?;
                    let download_url = Url::from_str(&download_url).or_raise(|| RepoError {
                        message: format!("cannot parse '{download_url}' download url"),
                    })?;
                    let hash: String = json_extract(filej, "attributes.extra.hashes.sha256")
                        .or_raise(|| RepoError {
                            message: "fail to extracting 'attributes.extra.hashes.sha256' as String from json"
                                .to_string(),
                        })?;
                    let checksum = Checksum::Sha256(hash);
                    let file = FileMeta::new(
                        dir.join(&name),
                        endpoint,
                        download_url,
                        Some(size),
                        vec![checksum],
                    );
                    entries.push(Entry::File(file));
                }
                "folder" => {
                    let api_url: String =
                        json_extract(filej, "relationships.files.links.related.href")
                        .or_raise(|| RepoError {
                            message: "fail to extracting 'relationships.files.links.related.href' as String from json"
                                .to_string(),
                        })?;
                    let api_url = Url::from_str(&api_url).or_raise(|| RepoError {
                        message: format!("cannot parse '{api_url}' api url"),
                    })?;
                    let dir = DirMeta::new(dir.join(&name), api_url, dir.root_url());
                    entries.push(Entry::Dir(dir));
                }
                typ => {
                    exn::bail!(RepoError {
                        message: format!(
                            "kind can be 'dataset' or 'kind' for an OSF entry, got {typ}"
                        )
                    });
                }
            }
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://datavers.example/api/datasets/:persistentId/versions/:latest-poblished/?persistentId=<id>
#[derive(Debug)]
pub struct DataverseDataset {
    base_url: Url,
    version: String,
}

impl DataverseDataset {
    #[must_use]
    pub fn new(base_url: Url, version: String) -> Self {
        DataverseDataset { base_url, version }
    }
}

#[async_trait]
impl Repository for DataverseDataset {
    fn root_url(&self, id: &str) -> Url {
        // "https://datavers.example/api/datasets/:persistentId/versions/:latest-poblished/?persistentId=doi:10.7910/DVN/KBHLOD"
        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        let mut url = self.base_url.clone();
        {
            let mut segments = url.path_segments_mut().unwrap();
            segments.extend([
                "api",
                "datasets",
                ":persistentId",
                "versions",
                &self.version, // e.g. ":latest-published"
            ]);
        }

        url.query_pairs_mut().append_pair("persistentId", id);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;

        let files = resp
            .get("data")
            .and_then(|d| d.get("files"))
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "field with key 'data.files' not resolve to an json array".to_string(),
            })?;

        let mut entries = Vec::with_capacity(files.len());
        for (idx, filej) in files.iter().enumerate() {
            let endpoint = Endpoint {
                parent_url: dir.api_url.clone(),
                key: Some(format!("data.files.{idx}")),
            };
            let name: String = json_extract(filej, "dataFile.filename").or_raise(|| RepoError {
                message: "fail to extracting 'dataFile.filename' as String from json".to_string(),
            })?;
            let id: u64 = json_extract(filej, "dataFile.id").or_raise(|| RepoError {
                message: "fail to extracting 'dataFile.id' as u64 from json".to_string(),
            })?;
            let size: u64 = json_extract(filej, "dataFile.filesize").or_raise(|| RepoError {
                message: "fail to extracting 'dataFile.filesize' as u64 from json".to_string(),
            })?;
            let download_url = "https://dataverse.harvard.edu/api/access/datafile/";
            let download_url = Url::from_str(download_url).or_raise(|| RepoError {
                message: format!("cannot parse '{download_url}' download base url"),
            })?;
            let download_url = download_url.join(&format!("{id}")).or_raise(|| RepoError {
                message: format!("cannot parse '{download_url}' download url"),
            })?;
            // XXX: Is dataverse only MD5 support? there is dataFile.checksum.value as well
            let hash: String = json_extract(filej, "dataFile.md5").or_raise(|| RepoError {
                message: "fail to extracting 'dataFile.md5' as String from json".to_string(),
            })?;
            let checksum = Checksum::Md5(hash);
            let file = FileMeta::new(
                dir.join(&name),
                endpoint,
                download_url,
                Some(size),
                vec![checksum],
            );
            entries.push(Entry::File(file));
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://datavers.example/api/files/:persistentId/versions/:latest-published/?persistentId=<id>
#[derive(Debug)]
pub struct DataverseFile {
    base_url: Url,
    version: String,
}

impl DataverseFile {
    #[must_use]
    pub fn new(base_url: Url, version: String) -> Self {
        DataverseFile { base_url, version }
    }
}

#[async_trait]
impl Repository for DataverseFile {
    fn root_url(&self, id: &str) -> Url {
        // "https://datavers.example/api/files/:persistentId/versions/:latest-poblished/?persistentId=doi:10.7910/DVN/KBHLOD/DHJ45U"
        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        let mut url = self.base_url.clone();
        {
            let mut segments = url.path_segments_mut().unwrap();
            segments.extend([
                "api",
                "files",
                ":persistentId",
                "versions",
                &self.version, // e.g. ":latest-published"
            ]);
        }

        url.query_pairs_mut().append_pair("persistentId", id);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;

        let filej = resp.get("data").ok_or_else(|| RepoError {
            message: "field with key 'data' not resolve to an json value".to_string(),
        })?;

        let name: String = json_extract(filej, "dataFile.filename").or_raise(|| RepoError {
            message: "fail to extracting 'dataFile.filename' as String from json".to_string(),
        })?;
        let id: u64 = json_extract(filej, "dataFile.id").or_raise(|| RepoError {
            message: "fail to extracting 'dataFile.id' as u64 from json".to_string(),
        })?;

        let size: u64 = json_extract(filej, "dataFile.filesize").or_raise(|| RepoError {
            message: "fail to extracting 'dataFile.filesize' as u64 from json".to_string(),
        })?;
        let download_url = "https://dataverse.harvard.edu/api/access/datafile/";
        let download_url = Url::from_str(download_url).or_raise(|| RepoError {
            message: format!("cannot parse '{download_url}' download base url"),
        })?;
        let download_url = download_url.join(&format!("{id}")).or_raise(|| RepoError {
            message: format!("cannot parse '{download_url}' download url"),
        })?;
        // XXX: Is dataverse only MD5 support? there is dataFile.checksum.value as well
        let hash: String = json_extract(filej, "dataFile.md5").or_raise(|| RepoError {
            message: "fail to extracting 'dataFile.md5' as String from json".to_string(),
        })?;
        let checksum = Checksum::Md5(hash);
        let endpoint = Endpoint {
            parent_url: dir.api_url.clone(),
            key: Some("data".to_string()),
        };
        let file = FileMeta::new(
            dir.join(&name),
            endpoint,
            download_url,
            Some(size),
            vec![checksum],
        );
        let entries = vec![Entry::File(file)];

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

pub struct GitHub {
    pub owner: String,
    pub repo: String,
}

impl GitHub {
    #[must_use]
    pub fn new(owner: &str, repo: &str) -> Self {
        GitHub {
            owner: owner.to_string(),
            repo: repo.to_string(),
        }
    }
}

fn github_branch_or_commit_from_url(url: &Url) -> Option<String> {
    let segments: Vec<&str> = url.path_segments()?.collect();

    // GitHub tree URL format:
    // ["repos", "owner", "repo", "git", "trees", "<branch_or_commit>"]
    //https://api.github.com/repos/rs4rse/vizmat/git/trees/main?recursive=1
    if segments.len() >= 6 && segments[3] == "git" && segments[4] == "trees" {
        Some(segments[5].to_string())
    } else {
        None
    }
}

#[async_trait]
impl Repository for GitHub {
    fn root_url(&self, id: &str) -> Url {
        // id for github repo is the commit hash or branch name

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        let mut url = Url::parse("https://api.github.com/repos").unwrap();
        url.path_segments_mut()
            .unwrap()
            .extend([&self.owner, &self.repo, "git", "trees", id]);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .map_err(|e| RepoError {
                message: format!("HTTP GET failed: {e}"),
            })?;
        // Check status code before calling `error_for_status`
        if resp.status() == StatusCode::FORBIDDEN {
            exn::bail!(RepoError {
                message: "GitHub API rate limit excceded. \
                    You may need to provide a personal access token via the `GITHUB_TOKEN` environment variable \
                ".to_string(),
            });
        }

        let resp = resp.error_for_status().map_err(|e| RepoError {
            message: format!("HTTP error GET {}: {}", dir.api_url, e),
        })?;

        let json: JsonValue = resp.json().await.map_err(|e| RepoError {
            message: format!("Failed to parse JSON from {}: {}", dir.api_url, e),
        })?;

        let tree = json
            .get("tree")
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "No 'tree' field in GitHub API response".to_string(),
            })?;

        let mut entries = Vec::with_capacity(tree.len());

        for (i, filej) in tree.iter().enumerate() {
            let path: String = json_extract(filej, "path").or_raise(|| RepoError {
                message: "Missing 'path' in tree entry".to_string(),
            })?;
            let kind: String = json_extract(filej, "type").or_raise(|| RepoError {
                message: "Missing 'type' in tree entry".to_string(),
            })?;

            let record_id = github_branch_or_commit_from_url(&dir.root_url())
                .expect("can parse branch or commit from url");
            match kind.as_ref() {
                "blob" => {
                    let size: u64 = json_extract(filej, "size").unwrap_or(0);
                    let path = dir.join(&path);
                    let download_url = format!(
                        "https://raw.githubusercontent.com/{}/{}/{}/{}",
                        self.owner,
                        self.repo,
                        record_id,
                        path.relative()
                    );
                    let download_url = Url::parse(&download_url).unwrap();

                    let file = FileMeta::new(
                        path,
                        Endpoint {
                            parent_url: dir.api_url.clone(),
                            key: Some(format!("tree.{i}")),
                        },
                        download_url,
                        Some(size),
                        vec![],
                    );
                    entries.push(Entry::File(file));
                }
                "tree" => {
                    let tree_url: String = json_extract(filej, "url").or_raise(|| RepoError {
                        message: "Missing 'url' in tree entry".to_string(),
                    })?;
                    let tree_url = Url::from_str(&tree_url).or_raise(|| RepoError {
                        message: format!("cannot parse '{tree_url}' api url"),
                    })?;
                    let dir = DirMeta::new(dir.join(&path), tree_url, dir.root_url());
                    entries.push(Entry::Dir(dir));
                }
                other => {
                    exn::bail!(RepoError {
                        message: format!("Unknown tree type: {other}"),
                    });
                }
            }
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://datadryad.org/
// API root url at https://datadryad.org/api/v2
#[derive(Debug)]
pub struct DataDryad {
    base_url: Url,
}

impl DataDryad {
    #[must_use]
    pub fn new(base_url: Url) -> Self {
        DataDryad { base_url }
    }
}

#[allow(clippy::too_many_lines)]
#[async_trait]
impl Repository for DataDryad {
    fn root_url(&self, id: &str) -> Url {
        // https://datadryad.org/api/v2/datasets/<id> to start for every dateset entry

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        // - `path_segments_mut` cannot fail for this URL scheme
        let mut url = Url::from_str("https://datadryad.org/api/v2/datasets").unwrap();
        url.path_segments_mut().unwrap().extend([id]);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;

        // get link to the api of latest version of dataset
        let version: String =
            json_extract(&resp, "_links.stash:version.href").or_raise(|| RepoError {
                message: "fail to extract '_links.stash:version.href' as string from json"
                    .to_string(),
            })?;

        // second http GET call to get files
        // safe to unwrap: because base_url is from url.
        let mut files_api_url = self.base_url.join(&version).or_raise(|| RepoError {
            message: format!(
                "cannot join version '{}' to base url '{}'",
                version,
                self.base_url.as_str()
            ),
        })?;
        files_api_url
            .path_segments_mut()
            .expect("url cannot be base")
            .extend(["files"]);
        let resp = client
            .get(files_api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {files_api_url}"),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {files_api_url}"),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {files_api_url}, network / protocol error"),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {files_api_url}, unable to convert to json"),
        })?;

        let files = resp
            .get("_embedded")
            .and_then(|d| d.get("stash:files"))
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "field with key '_embedded.stash:files' not resolve to an json array"
                    .to_string(),
            })?;
        let mut entries = Vec::with_capacity(files.len());
        for (idx, filej) in files.iter().enumerate() {
            let endpoint = Endpoint {
                parent_url: files_api_url.clone(),
                key: Some(format!("_embedded.stash:files.{idx}")),
            };
            let name: String = json_extract(filej, "path").or_raise(|| RepoError {
                message: "fail to extracting 'path' as String from json".to_string(),
            })?;
            let size: u64 = json_extract(filej, "size").or_raise(|| RepoError {
                message: "fail to extracting 'size' as u64 from json".to_string(),
            })?;
            let download_url_path: String =
                json_extract(filej, "_links.stash:download.href").or_raise(|| RepoError {
                   message: format!("fail to extracting '_links.stash:download' as String from json, at parsing {files_api_url}")
                })?;
            let download_url = self
                .base_url
                .join(&download_url_path)
                .or_raise(|| RepoError {
                    message: format!(
                        "fail to concat download_url from base_url '{}', and path '{}'",
                        self.base_url.as_str(),
                        download_url_path
                    ),
                })?;
            let hash_type: String = json_extract(filej, "digestType").or_raise(|| RepoError {
                message: "fail to extracting 'digestType' as String from json".to_string(),
            })?;
            let checksum = if hash_type.to_lowercase() == "md5" {
                let hash: String = json_extract(filej, "digest").or_raise(|| RepoError {
                    message:
                        "fail to extracting 'attributes.extra.hashes.sha256' as String from json"
                            .to_string(),
                })?;
                Checksum::Md5(hash)
            } else {
                exn::bail!(RepoError {
                    message: format!("unsupported hash type, '{hash_type}'")
                })
            };
            let file = FileMeta::new(
                dir.join(&name),
                endpoint,
                download_url,
                Some(size),
                vec![checksum],
            );
            entries.push(Entry::File(file));
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

// https://zenodo.org/
// API root url at https://zenodo.org/api/
#[derive(Debug)]
pub struct Zenodo;

impl Zenodo {
    #[must_use]
    pub fn new() -> Self {
        Zenodo {}
    }
}

impl Default for Zenodo {
    fn default() -> Self {
        Self::new()
    }
}

#[allow(clippy::too_many_lines)]
#[async_trait]
impl Repository for Zenodo {
    fn root_url(&self, id: &str) -> Url {
        // https://zenodo.org/api/<id> to start for every dateset entry

        // Safe to unwrap:
        // - the base URL is a hard-coded, valid absolute URL
        // - `path_segments_mut` cannot fail for this URL scheme
        let mut url = Url::from_str("https://zenodo.org/api/records").unwrap();
        url.path_segments_mut().unwrap().extend([id, "files"]);
        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .or_raise(|| RepoError {
                message: format!("fail at client sent GET {}", dir.api_url),
            })?;
        let resp = resp.error_for_status().map_err(|err| match err.status() {
            Some(StatusCode::NOT_FOUND) => RepoError {
                message: format!("resource not found when GET {}", dir.api_url),
            },
            Some(status_code) => RepoError {
                message: format!(
                    "fail GET {}, with state code: {}",
                    dir.api_url,
                    status_code.as_str()
                ),
            },
            None => RepoError {
                message: format!("fail GET {}, network / protocol error", dir.api_url,),
            },
        })?;
        let resp: JsonValue = resp.json().await.or_raise(|| RepoError {
            message: format!("fail GET {}, unable to convert to json", dir.api_url,),
        })?;

        let files = resp
            .get("entries")
            .and_then(JsonValue::as_array)
            .ok_or_else(|| RepoError {
                message: "field with key '_embedded.stash:files' not resolve to an json array"
                    .to_string(),
            })?;
        let mut entries = Vec::with_capacity(files.len());
        for (idx, filej) in files.iter().enumerate() {
            let endpoint = Endpoint {
                parent_url: dir.api_url.clone(),
                key: Some(format!("entries.{idx}")),
            };
            let name: String = json_extract(filej, "key").or_raise(|| RepoError {
                message: "fail to extracting 'path' as String from json".to_string(),
            })?;
            let size: u64 = json_extract(filej, "size").or_raise(|| RepoError {
                message: "fail to extracting 'size' as u64 from json".to_string(),
            })?;
            let download_url: String =
                json_extract(filej, "links.content").or_raise(|| RepoError {
                   message: format!("fail to extracting '_links.stash:download' as String from json, at parsing {}", dir.api_url)
                })?;
            let download_url = Url::from_str(&download_url).or_raise(|| RepoError {
                message: format!("fail to parse download_url from base_url '{download_url}'"),
            })?;
            let checksum: String = json_extract(filej, "checksum").or_raise(|| RepoError {
                message: "fail to extracting 'checksum' as String from json".to_string(),
            })?;
            let mut checksum_split = checksum.split(':');
            let checksum = match checksum_split.next() {
                Some("md5") => {
                    if let Some(checksum) = checksum_split.next() {
                        Checksum::Md5(checksum.to_lowercase())
                    } else {
                        exn::bail!(RepoError {
                            message: "checksum format is wrong, type md5 but no checksum"
                                .to_string()
                        })
                    }
                }
                Some("sha256") => {
                    if let Some(checksum) = checksum_split.next() {
                        Checksum::Sha256(checksum.to_lowercase())
                    } else {
                        exn::bail!(RepoError {
                            message: "checksum format is wrong, type sha256 but no checksum"
                                .to_string()
                        })
                    }
                }
                _ => exn::bail!(RepoError {
                    message: "checksum field is wrong".to_string()
                }),
            };
            let file = FileMeta::new(
                dir.join(&name),
                endpoint,
                download_url,
                Some(size),
                vec![checksum],
            );
            entries.push(Entry::File(file));
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}

#[derive(Debug)]
pub struct HuggingFace {
    owner: String,
    repo: String,
    revision: String,
}

impl HuggingFace {
    #[must_use]
    pub fn new(owner: &str, repo: &str, revision: &str) -> Self {
        HuggingFace {
            owner: owner.to_string(),
            repo: repo.to_string(),
            revision: revision.to_string(),
        }
    }
}

impl HuggingFace {
    fn download_url(&self, path: &str) -> Url {
        // https://huggingface.co/datasets/{repo_id}/resolve/{revision}/{path}
        let mut url = Url::parse("https://huggingface.co/datasets").unwrap();
        url.path_segments_mut()
            .unwrap()
            .extend([&self.owner, &self.repo, "resolve", &self.revision])
            .extend(path.split('/'));
        url
    }
}

#[async_trait]
impl Repository for HuggingFace {
    fn root_url(&self, _id: &str) -> Url {
        // https://huggingface.co/api/datasets/{owner}/{repo}/tree/{revision}/{path}
        let mut url = Url::parse("https://huggingface.co/api/datasets").unwrap();
        // safe to unwrap, we know the url.
        url.path_segments_mut()
            .unwrap()
            .extend([&self.owner, &self.repo, "tree", &self.revision]);

        url
    }

    async fn list(&self, client: &Client, dir: DirMeta) -> Result<Vec<Entry>, Exn<RepoError>> {
        let resp = client
            .get(dir.api_url.clone())
            .send()
            .await
            .map_err(|e| RepoError {
                message: format!("HTTP GET failed: {e}"),
            })?;

        if resp.status() == StatusCode::FORBIDDEN {
            exn::bail!(RepoError {
                message: "Hugging Face API rate limit exceeded".to_string(),
            });
        }

        let resp = resp.error_for_status().map_err(|e| RepoError {
            message: format!("HTTP error GET {}: {e}", dir.api_url),
        })?;

        let json: JsonValue = resp.json().await.map_err(|e| RepoError {
            message: format!("Failed to parse JSON from {}: {e}", dir.api_url),
        })?;

        let files = json.as_array().ok_or_else(|| RepoError {
            message: "Expected array from Hugging Face tree API".to_string(),
        })?;

        let mut entries = Vec::with_capacity(files.len());

        for (i, filej) in files.iter().enumerate() {
            let path: String = json_extract(filej, "path").or_raise(|| RepoError {
                message: "Missing 'path'".to_string(),
            })?;
            let path = path.split('/').next_back().ok_or_raise(|| RepoError {
                message: "not get the basename of path".to_string(),
            })?;
            let kind: String = json_extract(filej, "type").or_raise(|| RepoError {
                message: "Missing 'type'".to_string(),
            })?;

            match kind.as_str() {
                "file" => {
                    let size: u64 = json_extract(filej, "size").or_raise(|| RepoError {
                        message: format!("Missing size from {}", dir.api_url),
                    })?;
                    let checksum: String = json_extract(filej, "lfs.oid")
                        .or_else(|_| json_extract(filej, "oid"))
                        .or_raise(|| RepoError {
                            message: format!("Missing 'lfs.oid' from {}", dir.api_url),
                        })?;
                    let checksum = Checksum::Sha256(checksum);
                    let path = dir.join(path);

                    let download_url = self.download_url(path.relative().as_str());

                    let file = FileMeta::new(
                        path,
                        Endpoint {
                            parent_url: dir.api_url.clone(),
                            key: Some(format!("filej.{i}")),
                        },
                        download_url,
                        Some(size),
                        vec![checksum],
                    );

                    entries.push(Entry::File(file));
                }
                "directory" => {
                    let mut api_url = dir.root_url();
                    // huggingface, path field return the relative path to the root, not to the
                    // parent folder.
                    api_url
                        .path_segments_mut()
                        .map_err(|err| RepoError {
                            message: format!("path_segments_mut fail with {err:?}"),
                        })?
                        .extend([path]);
                    let subdir = DirMeta::new(dir.join(path), api_url.clone(), api_url.clone());
                    entries.push(Entry::Dir(subdir));
                }
                other => {
                    exn::bail!(RepoError {
                        message: format!("Unknown HF entry type: {other}"),
                    });
                }
            }
        }

        Ok(entries)
    }

    fn as_any(&self) -> &dyn Any {
        self
    }
}
